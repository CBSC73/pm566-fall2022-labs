---
title: "Homework 3"
author: "CB"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---


```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
### Load required libraries
```{r, results='hide'}
library(data.table)
library(dplyr)
library(tidyverse)
library(dtplyr)
library(knitr)
library(ggplot2)
library(rvest)
library(httr)
library(xml2)
library(stringr)
```
## Part 1: APIs 

```{r}
# Downloading the website
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2%20trial%20vaccine")

# Finding the counts

counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[2]/div[1]/div[1]")

counts <- as.character(counts)
counts

# Extracting the data using regex
stringr::str_extract(counts, "[0-9,]+")
```
### _There are 3,997 results from this search_

### Create database
```{r}
query_ids <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
  query = list(
    db      = "pubmed",
    term    = "sars-cov-2 trial vaccine",
    retmax  = 250
  ), 
)
```
```{r}
# Extracting, make character
ids <- httr::content(query_ids)
ids <- as.character(ids)
```


```{r}
ids <- stringr::str_extract_all(ids, "<Id>[[:digit:]]+</Id>")[[1]]
# Remove all the leading and trailing <Id> </Id>. 
ids <- stringr::str_remove_all(ids, "</?Id>")
head(ids)
```

```{r}
publications <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi",
  query = list(
    db  = "pubmed",
    id  = paste(ids,collapse = ","),
  retmax = 250,
  rettype = "abstract"
    )
)
# Extracting the content of the response of GET
publications <- httr::content(publications)

publications_txt <- as.character(publications)

```

### Create a dataset containing Pubmed ID number,Title of the paper,Name of the journal where it was published,Publication date, and Abstract of the paper (if any).
```{r}
pub_char_list <- xml2::xml_children(publications)
pub_char_list <- sapply(pub_char_list, as.character)

```
```{r, get titles}
titles <- str_extract(pub_char_list, "<ArticleTitle>[[:print:][:space:]]+</ArticleTitle>")
titles[[1]]
titles <- str_remove_all(titles, "</?[[:alnum:]- =\"]+>")
titles[[1]]
```

```{r, get name of journal}
journalname <- str_extract(pub_char_list, "<Title>[[:print:][:space:]]+</Title>")
journalname[[1]]
journalname <- str_remove_all(journalname, "</?[[:alnum:]- =\"]+>")
journalname[[1]]

```

```{r, get abstracts}
abstracts <- str_extract(pub_char_list, "<Abstract>[[:print:][:space:]]+</Abstract>")
abstracts[[1]]
abstracts <- str_remove_all(abstracts, "</?[[:alnum:]- =\"]+>") 
abstracts[[1]]
abstracts <- str_replace_all(abstracts, "[[:space:]]+"," ")
abstracts[[1]]

```
```{r, get publication year}
pubyear <- str_extract(pub_char_list, "<Year>[0-9]{4}</Year>")
pubyear[[1]]
pubyear <- str_remove_all(pubyear, "</?[[:alnum:]- =\"]+>")
pubyear[[1]]

```
```{r, get publication month}
pubmonth <- str_extract(pub_char_list, "<Month>[a-zA-Z]{3}</Month>")
pubmonth[[1]]
pubmonth <- str_remove_all(pubmonth, "</?[[:alnum:]- =\"]+>")
pubmonth[[1]]

```

```{r, get publication day}
pubday <- str_extract(pub_char_list, "<Day>[0-9]{1,2}</Day>")
pubday[[1]]
pubday <- str_remove_all(pubday, "</?[[:alnum:]- =\"]+>")
pubday[[1]]
```
### Make a table with the dataset information 

```{r}

#Create publication date variable
pubdate <- paste(pubmonth, pubday, pubyear, sep="-")
pubdate[[1]]
  
```
```{r}
#Create table with all elements
database <- data.frame(
  PubMedId = ids,
  Title    = titles,
  Abstract = abstracts,
  Journal =journalname,
  Publication_Date=pubdate
  
)
knitr::kable(database[1:10,], caption = "Covid-19 Vaccine Trials Papers")
```


